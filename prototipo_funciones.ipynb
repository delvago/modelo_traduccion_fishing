{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c83bd49",
   "metadata": {},
   "source": [
    "# Modelo de traducción de texto\n",
    "El modelo de phishing parece funcionar tanto en español como en inglés, pero por razones de confiabilidad, utilizaremos un modelo traductor primero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8cf632dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, pipeline\n",
    "from torch import argmax, softmax\n",
    "# Modelo de traducción\n",
    "tokenizer_traductor = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
    "model_traductor = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d69e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traductor(text):\n",
    "    input = tokenizer_traductor(text, return_tensors=\"pt\", padding=True)\n",
    "    output = model_traductor.generate(**input)\n",
    "    traduccion = tokenizer_traductor.batch_decode(output, skip_special_tokens=True)\n",
    "    return traduccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4d2c97a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, World.', 'If you do not check your account within the next 24 hours, we may be forced to impose additional restrictions or suspend your account permanently for security reasons. Protecting your information is our priority. If it was not you who did this activity, we recommend that you change your password immediately after verifying your identity through the proposed link.', \"I don't want to, you do.\"]\n"
     ]
    }
   ],
   "source": [
    "# Reemplazar con la conexión a base de datos\n",
    "lista_textos = [\n",
    "    \"Hola Mundo\",\n",
    "    \"Si no verificas tu cuenta en las próximas 24 horas, podríamos vernos obligados a imponer restricciones adicionales o suspensor tu cuenta de forma permanente por motivos de seguridad. Proteger tu información es nuestra prioridad. Si no fue tú quien realizó esta actividad, te recomendamos que cambie tu contraseña inmediatamente después de verificar tu identidad a través del enlace propuesto.\",\n",
    "    \"No quiero, hazlo tu\"\n",
    "]\n",
    "\n",
    "traducciones_lista = traductor(lista_textos)\n",
    "print(traducciones_lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05598e48",
   "metadata": {},
   "source": [
    "# Modelo de detección de phishing ealvatadob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e843468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de phishing\n",
    "tokenizer_phishing = AutoTokenizer.from_pretrained(\"ealvaradob/bert-finetuned-phishing\")\n",
    "model_phishing = AutoModelForSequenceClassification.from_pretrained(\"ealvaradob/bert-finetuned-phishing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ee5beb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phishing(text):\n",
    "    input = tokenizer_phishing(text, return_tensors=\"pt\", padding=True)\n",
    "    output = model_phishing(**input)\n",
    "    logits = output.logits\n",
    "    probabilidades = logits.softmax(dim=1)\n",
    "    prediccion_id = argmax(probabilidades, dim=1)\n",
    "    lista_resultados = []\n",
    "    \n",
    "    for i in range(len(prediccion_id)):\n",
    "        pred_id = prediccion_id[i].item()\n",
    "        etiqueta_predicha = model_phishing.config.id2label[pred_id]\n",
    "        prob_predicha = probabilidades[i, pred_id].item()\n",
    "\n",
    "        resultado = {   \n",
    "            \"prediccion\" : \"phishing\" if etiqueta_predicha == \"phishing\" else \"benigno\",\n",
    "            \"probabilidad\" : prob_predicha\n",
    "        }\n",
    "        lista_resultados.append(resultado)\n",
    "    return lista_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a02ec3",
   "metadata": {},
   "source": [
    "# Modelo de detección de Phishing ElSlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"ElSlay/BERT-Phishing-Email-Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95266173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phishing_pipe(text):\n",
    "    resultado = pipe(text)\n",
    "    lista_resultados = []\n",
    "    for i in range(len(resultado)):\n",
    "        pred_id = resultado[i]['label']\n",
    "        prob_predicha = resultado[i]['score']\n",
    "\n",
    "        resultado = {   \n",
    "            \"prediccion\" : \"phishing\" if pred_id == \"LABEL_1\" else \"benigno\",\n",
    "            \"probabilidad\" : prob_predicha\n",
    "        }\n",
    "        lista_resultados.append(resultado)\n",
    "    return lista_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb5117",
   "metadata": {},
   "source": [
    "# Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e348113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(text):\n",
    "    traduccion = traductor(text)\n",
    "    resultado = phishing(traduccion)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a9c31c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correo(text):\n",
    "    resultado = phishing(text)\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fb0d3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prediccion': 'benigno', 'probabilidad': 0.9975121021270752}, {'prediccion': 'phishing', 'probabilidad': 0.9996534585952759}, {'prediccion': 'benigno', 'probabilidad': 0.9999877214431763}]\n"
     ]
    }
   ],
   "source": [
    "resultado = prediccion(lista_textos)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7635fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"hello, delva: here's a reminder that your trial of google one (google ai pro (2 tb)) on google play will end on may 29, 2025. you will be automatically charged as described below in the payment method provided unless you cancel earlier. you can cancel your subscription and view upcoming charges at any time in the subscriptions section of google play. see how to cancel your subscription. summary next payment $79,000.00/month payment date may 29, 2025 keep this message in case you need it in the future. see google play's refund policy and terms of service. see google play order history. see google play's refund policy and terms of service you received this email reminder because you signed up for a subscription that starts with a trial. (c) 2025 google llc 1600 amphitheatre parkway, mountain view, ca 94043 do not reply to this email, as we cannot use this address to reply to you. if you need help, please visit the google play help center.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3371dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prediccion': 'phishing', 'probabilidad': 0.9998579025268555}]\n"
     ]
    }
   ],
   "source": [
    "# Modelo aelvatado\n",
    "print(phishing(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe50c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prediccion': 'benigno', 'probabilidad': 0.9046099185943604}]\n"
     ]
    }
   ],
   "source": [
    "# Modelo ElSlay\n",
    "print(phishing_pipe(texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69261ea1",
   "metadata": {},
   "source": [
    "# Limpieza HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e884f1fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbs4\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup, Comment\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclean_html_content\u001b[39m(html_content):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import re\n",
    "\n",
    "def clean_html_content(html_content):\n",
    "    \"\"\"\n",
    "    Limpia el contenido HTML para extraer el texto visible. # Docstring original del usuario restaurado\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        return \"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Eliminar etiquetas de script y style\n",
    "    for script_or_style in soup([\"script\", \"style\", \"head\", \"meta\", \"link\"]):\n",
    "        script_or_style.decompose()\n",
    "\n",
    "    # Eliminar comentarios HTML\n",
    "    for comment_tag in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment_tag.extract() \n",
    "\n",
    "    # Reemplazar <br> con saltos de línea\n",
    "    for br_tag in soup.find_all(\"br\"):\n",
    "        br_tag.replace_with(\"\\n\")\n",
    "\n",
    "    # Obtener el texto\n",
    "    text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    # Normalizar múltiples saltos de línea y eliminar líneas vacías\n",
    "    lines = [line for line in text.splitlines() if line.strip()] # Procesa las líneas para eliminar las vacías\n",
    "    cleaned_text_html = \"\\n\".join(lines) # Une las líneas limpias con un solo salto de línea\n",
    "    \n",
    "    # Eliminar URLs usando expresiones regulares\n",
    "    # Esta expresión regular busca patrones comunes de URL (http, https, ftp, www)\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|www\\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    cleaned_text_no_urls = re.sub(url_pattern, '', cleaned_text_html) # Elimina las URLs encontradas\n",
    "    \n",
    "    # Re-procesar líneas después de la eliminación de URLs para asegurar que todas las líneas vacías (o que quedaron vacías después del strip) se eliminen,\n",
    "    # y luego colapsar múltiples saltos de línea que pudieran persistir.\n",
    "    lines_after_url_removal = [line.strip() for line in cleaned_text_no_urls.splitlines()] # Divide en líneas y quita espacios en blanco de cada una\n",
    "    non_empty_lines_after_url_removal = [line for line in lines_after_url_removal if line] # Filtra las líneas que quedaron completamente vacías (después de strip)\n",
    "    text_reassembled = \"\\n\".join(non_empty_lines_after_url_removal) # Vuelve a unir con un solo salto de línea\n",
    "    \n",
    "    # Colapso final de múltiples saltos de línea (aunque el paso anterior debería manejar la mayoría de los casos)\n",
    "    # y eliminar cualquier espacio en blanco al inicio o final de todo el texto.\n",
    "    cleaned_text_final = re.sub(r'\\n{2,}', '\\n', text_reassembled).strip() \n",
    "    \n",
    "    return cleaned_text_final # Devuelve el texto procesado, sin URLs y con saltos de línea normalizados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
